{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nimport re\nimport string \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\nimport tensorflow as tf\nfrom tensorflow import keras\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.preprocessing import text,sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Embedding,LSTM,Dropout","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:12.792377Z","iopub.execute_input":"2022-04-18T03:09:12.792712Z","iopub.status.idle":"2022-04-18T03:09:18.847444Z","shell.execute_reply.started":"2022-04-18T03:09:12.792629Z","shell.execute_reply":"2022-04-18T03:09:18.846483Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install -q -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:18.849287Z","iopub.execute_input":"2022-04-18T03:09:18.849570Z","iopub.status.idle":"2022-04-18T03:09:28.710622Z","shell.execute_reply.started":"2022-04-18T03:09:18.849527Z","shell.execute_reply":"2022-04-18T03:09:28.709847Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras_tuner as kt","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:28.712488Z","iopub.execute_input":"2022-04-18T03:09:28.712787Z","iopub.status.idle":"2022-04-18T03:09:29.154147Z","shell.execute_reply.started":"2022-04-18T03:09:28.712734Z","shell.execute_reply":"2022-04-18T03:09:29.153311Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"real_data = pd.read_csv('../input/tf-data/True.csv')\nfake_data = pd.read_csv('../input/tf-data/Fake.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:29.156627Z","iopub.execute_input":"2022-04-18T03:09:29.157204Z","iopub.status.idle":"2022-04-18T03:09:31.395744Z","shell.execute_reply.started":"2022-04-18T03:09:29.157162Z","shell.execute_reply":"2022-04-18T03:09:31.395022Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"real_data['target'] = 1\nfake_data['target'] = 0","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:31.398876Z","iopub.execute_input":"2022-04-18T03:09:31.399078Z","iopub.status.idle":"2022-04-18T03:09:31.410980Z","shell.execute_reply.started":"2022-04-18T03:09:31.399054Z","shell.execute_reply":"2022-04-18T03:09:31.410266Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([real_data, fake_data], ignore_index=True, sort=False)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:31.412167Z","iopub.execute_input":"2022-04-18T03:09:31.412447Z","iopub.status.idle":"2022-04-18T03:09:31.434887Z","shell.execute_reply.started":"2022-04-18T03:09:31.412397Z","shell.execute_reply":"2022-04-18T03:09:31.434126Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0  As U.S. budget fight looms, Republicans flip t...   \n1  U.S. military to accept transgender recruits o...   \n2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n3  FBI Russia probe helped by Australian diplomat...   \n4  Trump wants Postal Service to charge 'much mor...   \n\n                                                text       subject  \\\n0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n\n                 date  target  \n0  December 31, 2017        1  \n1  December 29, 2017        1  \n2  December 31, 2017        1  \n3  December 30, 2017        1  \n4  December 29, 2017        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>politicsNews</td>\n      <td>December 30, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['text']= data['subject'] + \" \" + data['title'] + \" \" + data['text']\ndel data['title']\ndel data['subject']\ndel data['date']\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:31.436096Z","iopub.execute_input":"2022-04-18T03:09:31.436400Z","iopub.status.idle":"2022-04-18T03:09:31.604573Z","shell.execute_reply.started":"2022-04-18T03:09:31.436365Z","shell.execute_reply":"2022-04-18T03:09:31.603797Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text  target\n0  politicsNews As U.S. budget fight looms, Repub...       1\n1  politicsNews U.S. military to accept transgend...       1\n2  politicsNews Senior U.S. Republican senator: '...       1\n3  politicsNews FBI Russia probe helped by Austra...       1\n4  politicsNews Trump wants Postal Service to cha...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>politicsNews As U.S. budget fight looms, Repub...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>politicsNews U.S. military to accept transgend...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>politicsNews Senior U.S. Republican senator: '...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>politicsNews FBI Russia probe helped by Austra...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>politicsNews Trump wants Postal Service to cha...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.dropna()\ndata.fillna(\"\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:31.605879Z","iopub.execute_input":"2022-04-18T03:09:31.606187Z","iopub.status.idle":"2022-04-18T03:09:31.626790Z","shell.execute_reply.started":"2022-04-18T03:09:31.606152Z","shell.execute_reply":"2022-04-18T03:09:31.626158Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pip install bs4","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:31.627858Z","iopub.execute_input":"2022-04-18T03:09:31.628171Z","iopub.status.idle":"2022-04-18T03:09:41.002801Z","shell.execute_reply.started":"2022-04-18T03:09:31.628135Z","shell.execute_reply":"2022-04-18T03:09:41.001872Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting bs4\n  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from bs4) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.3.1)\nBuilding wheels for collected packages: bs4\n  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=3ed483364eabf2304beca4dc16cfb890991b8109de4eae26f4f23e971e6f9988\n  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\nSuccessfully built bs4\nInstalling collected packages: bs4\nSuccessfully installed bs4-0.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nfrom bs4 import BeautifulSoup\nnltk.download(\"stopwords\")   \nfrom nltk.corpus import stopwords\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:41.007038Z","iopub.execute_input":"2022-04-18T03:09:41.007268Z","iopub.status.idle":"2022-04-18T03:09:41.401104Z","shell.execute_reply.started":"2022-04-18T03:09:41.007241Z","shell.execute_reply":"2022-04-18T03:09:41.400305Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def remove_characters(text):\n    return re.sub(\"[^a-zA-Z]\",\" \",text)\n\n#Removal of stopwords \ndef remove_stopwords_and_lemmatization(text):\n    final_text = []\n    text = text.lower()\n    text = nltk.word_tokenize(text)\n    \n    for word in text:\n        if word not in set(stopwords.words('english')):\n            lemma = nltk.WordNetLemmatizer()\n            word = lemma.lemmatize(word) \n            final_text.append(word)\n    return \" \".join(final_text)\n\n#Total function\ndef cleaning(text):\n    text = remove_characters(text)\n    text = remove_stopwords_and_lemmatization(text)\n    return text\n\n#Apply function on text column\ndata['text']=data['text'].apply(cleaning)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:41.402888Z","iopub.execute_input":"2022-04-18T03:09:41.403438Z","iopub.status.idle":"2022-04-18T03:54:33.323686Z","shell.execute_reply.started":"2022-04-18T03:09:41.403393Z","shell.execute_reply":"2022-04-18T03:54:33.322831Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data=data.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:33.325056Z","iopub.execute_input":"2022-04-18T03:54:33.325486Z","iopub.status.idle":"2022-04-18T03:54:33.339940Z","shell.execute_reply.started":"2022-04-18T03:54:33.325447Z","shell.execute_reply":"2022-04-18T03:54:33.339117Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:33.341485Z","iopub.execute_input":"2022-04-18T03:54:33.341977Z","iopub.status.idle":"2022-04-18T03:54:33.365497Z","shell.execute_reply.started":"2022-04-18T03:54:33.341938Z","shell.execute_reply":"2022-04-18T03:54:33.364841Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                    text  target\n23236  news dan rather say every person moral compass...       0\n41837  left news hillary clinton super detailed count...       0\n18016  worldnews militant attack checkpoint somalia p...       1\n9385   politicsnews eight protester arrested trump ra...       1\n15512  worldnews trump visit could turning point nort...       1\n...                                                  ...     ...\n2667   politicsnews u lawmaker acknowledges corporate...       1\n43847  u news trump latest tease pale next bush gore ...       0\n3178   politicsnews white house yet plan debt limit b...       1\n8652   politicsnews woman male dominated career field...       1\n44299  middle east hollywood suffers meltdown trump w...       0\n\n[44898 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23236</th>\n      <td>news dan rather say every person moral compass...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41837</th>\n      <td>left news hillary clinton super detailed count...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18016</th>\n      <td>worldnews militant attack checkpoint somalia p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9385</th>\n      <td>politicsnews eight protester arrested trump ra...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15512</th>\n      <td>worldnews trump visit could turning point nort...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2667</th>\n      <td>politicsnews u lawmaker acknowledges corporate...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43847</th>\n      <td>u news trump latest tease pale next bush gore ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3178</th>\n      <td>politicsnews white house yet plan debt limit b...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8652</th>\n      <td>politicsnews woman male dominated career field...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44299</th>\n      <td>middle east hollywood suffers meltdown trump w...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>44898 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train1, X_test, y_train1, y_test = train_test_split(data['text'], data['target'],test_size=0.1 ,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:33.369553Z","iopub.execute_input":"2022-04-18T03:54:33.371713Z","iopub.status.idle":"2022-04-18T03:54:33.387919Z","shell.execute_reply.started":"2022-04-18T03:54:33.369951Z","shell.execute_reply":"2022-04-18T03:54:33.387268Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_lvl, X_unl, y_lvl, y_unl = train_test_split(X_train1,y_train1,test_size=0.70,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:33.391846Z","iopub.execute_input":"2022-04-18T03:54:33.394020Z","iopub.status.idle":"2022-04-18T03:54:33.408713Z","shell.execute_reply.started":"2022-04-18T03:54:33.393983Z","shell.execute_reply":"2022-04-18T03:54:33.408131Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"max_features = 3000\nmaxlen = 50","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:33.412432Z","iopub.execute_input":"2022-04-18T03:54:33.414392Z","iopub.status.idle":"2022-04-18T03:54:33.419427Z","shell.execute_reply.started":"2022-04-18T03:54:33.414349Z","shell.execute_reply":"2022-04-18T03:54:33.418613Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X_lvl)\ntokenized_train = tokenizer.texts_to_sequences(X_lvl)\nX_lvl = sequence.pad_sequences(tokenized_train, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:33.424143Z","iopub.execute_input":"2022-04-18T03:54:33.426368Z","iopub.status.idle":"2022-04-18T03:54:37.789024Z","shell.execute_reply.started":"2022-04-18T03:54:33.426330Z","shell.execute_reply":"2022-04-18T03:54:37.788280Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenized_test = tokenizer.texts_to_sequences(X_test)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:37.790747Z","iopub.execute_input":"2022-04-18T03:54:37.791159Z","iopub.status.idle":"2022-04-18T03:54:38.411574Z","shell.execute_reply.started":"2022-04-18T03:54:37.791122Z","shell.execute_reply":"2022-04-18T03:54:38.410792Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenized_unl = tokenizer.texts_to_sequences(X_unl)\nX_unl = sequence.pad_sequences(tokenized_unl, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:38.412999Z","iopub.execute_input":"2022-04-18T03:54:38.413265Z","iopub.status.idle":"2022-04-18T03:54:42.204348Z","shell.execute_reply.started":"2022-04-18T03:54:38.413228Z","shell.execute_reply":"2022-04-18T03:54:42.203591Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch_size = 128","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:42.205652Z","iopub.execute_input":"2022-04-18T03:54:42.205923Z","iopub.status.idle":"2022-04-18T03:54:42.210156Z","shell.execute_reply.started":"2022-04-18T03:54:42.205888Z","shell.execute_reply":"2022-04-18T03:54:42.209448Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import regularizers\n\ndef build_model(hp):\n    model = Sequential()\n    neurons = hp.Choice('units', values=[32,64, 128,256])\n    model.add(Embedding(max_features, output_dim=100, input_length=maxlen, trainable=False))\n    model.add(LSTM(units=neurons , return_sequences = True , recurrent_dropout =0.25,dropout=0.25))\n    model.add(LSTM(units=neurons , recurrent_dropout = 0.25 , dropout = 0.25))\n    model.add(Dense(units=neurons , activation = 'relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3])\n    model.compile(tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:42.211428Z","iopub.execute_input":"2022-04-18T03:54:42.212084Z","iopub.status.idle":"2022-04-18T03:54:42.222557Z","shell.execute_reply.started":"2022-04-18T03:54:42.212046Z","shell.execute_reply":"2022-04-18T03:54:42.221833Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tuner = kt.Hyperband(build_model,\n                     objective='val_accuracy',\n                     max_epochs=5,\n                     factor=3)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:42.223677Z","iopub.execute_input":"2022-04-18T03:54:42.224091Z","iopub.status.idle":"2022-04-18T03:54:44.869819Z","shell.execute_reply.started":"2022-04-18T03:54:42.224054Z","shell.execute_reply":"2022-04-18T03:54:44.869106Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2022-04-18 03:54:42.311842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:42.405991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:42.406842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:42.408246: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-18 03:54:42.409357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:42.410144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:42.410863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:44.265287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:44.266128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:44.266822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-18 03:54:44.267418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:44.870862Z","iopub.execute_input":"2022-04-18T03:54:44.871110Z","iopub.status.idle":"2022-04-18T03:54:44.877390Z","shell.execute_reply.started":"2022-04-18T03:54:44.871079Z","shell.execute_reply":"2022-04-18T03:54:44.876656Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_lvl,y_lvl, epochs=10, validation_split=0.2, callbacks=[stop_early])\n# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:54:44.878683Z","iopub.execute_input":"2022-04-18T03:54:44.879231Z","iopub.status.idle":"2022-04-18T05:11:10.316626Z","shell.execute_reply.started":"2022-04-18T03:54:44.879193Z","shell.execute_reply":"2022-04-18T05:11:10.315840Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Trial 10 Complete [00h 11m 26s]\nval_accuracy: 0.5282474160194397\n\nBest val_accuracy So Far: 0.9344329833984375\nTotal elapsed time: 01h 16m 25s\n","output_type":"stream"}]},{"cell_type":"code","source":"#model=build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:11:10.318053Z","iopub.execute_input":"2022-04-18T05:11:10.318366Z","iopub.status.idle":"2022-04-18T05:11:10.322445Z","shell.execute_reply.started":"2022-04-18T05:11:10.318331Z","shell.execute_reply":"2022-04-18T05:11:10.321661Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"maxitr=3\nitera=0\nminconf=0.75\ntl=len(data)-len(X_test)\nixll=len(X_lvl)\nixul=len(X_unl)\nX_train=X_lvl\ny_train=y_lvl\nmodel=tuner.hypermodel.build(best_hps)\nhistory = model.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=batch_size, shuffle=True, verbose = 1)\nwhile(len(X_unl)>0):\n    pred1=(model.predict(X_unl))\n    pred0=1-pred1\n    df_pred_prob = pd.DataFrame([])\n    df_pred_prob['prob_0'] = (pred0).tolist()\n    df_pred_prob['prob_1'] = (pred1).tolist()\n    df_pred_prob['text']=X_unl.tolist()\n    df=df_pred_prob\n    yln=[]\n    Xln=[]\n    Xun=[]\n    for i in range(len(X_unl)):\n        if((df['prob_0'][i][0])>minconf):\n            yln=yln+[0]\n            Xln=Xln+[df['text'][i]]\n        elif((df['prob_1'][i][0])>minconf):\n            yln=yln+[1]\n            Xln=Xln+[df['text'][i]]\n        else:\n            Xun=Xun+[df['text'][i]]\n    \n    y_train=np.concatenate((y_train,yln),axis=0)\n    X_train=np.concatenate((X_train,Xln),axis=0)\n    ixll=len(X_train)\n    print(\"length of train data:=\")\n    print(ixll)\n    model=tuner.hypermodel.build(best_hps)\n    history = model.fit(X_train, y_train, validation_split=0.3, epochs=50, batch_size=batch_size, shuffle=True, verbose = 1)\n    X_unl = np.array(Xun)\n    print(\"length of remaining unlabled data:=\")\n    print(len(X_unl))\n    itera=itera+1\n    if (itera==maxitr):\n        break\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-18T05:11:10.323899Z","iopub.execute_input":"2022-04-18T05:11:10.324347Z","iopub.status.idle":"2022-04-18T10:03:24.961741Z","shell.execute_reply.started":"2022-04-18T05:11:10.324313Z","shell.execute_reply":"2022-04-18T10:03:24.960990Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/100\n67/67 [==============================] - 34s 445ms/step - loss: 0.4413 - accuracy: 0.7743 - val_loss: 0.2724 - val_accuracy: 0.8859\nEpoch 2/100\n67/67 [==============================] - 30s 444ms/step - loss: 0.2900 - accuracy: 0.8810 - val_loss: 0.2623 - val_accuracy: 0.8944\nEpoch 3/100\n67/67 [==============================] - 30s 446ms/step - loss: 0.2602 - accuracy: 0.8915 - val_loss: 0.3002 - val_accuracy: 0.8578\nEpoch 4/100\n67/67 [==============================] - 29s 435ms/step - loss: 0.2582 - accuracy: 0.8952 - val_loss: 0.2222 - val_accuracy: 0.9104\nEpoch 5/100\n67/67 [==============================] - 30s 448ms/step - loss: 0.2305 - accuracy: 0.9067 - val_loss: 0.2184 - val_accuracy: 0.9148\nEpoch 6/100\n67/67 [==============================] - 30s 451ms/step - loss: 0.2138 - accuracy: 0.9192 - val_loss: 0.2039 - val_accuracy: 0.9241\nEpoch 7/100\n67/67 [==============================] - 29s 440ms/step - loss: 0.1983 - accuracy: 0.9248 - val_loss: 0.2021 - val_accuracy: 0.9189\nEpoch 8/100\n67/67 [==============================] - 29s 432ms/step - loss: 0.1900 - accuracy: 0.9274 - val_loss: 0.2002 - val_accuracy: 0.9200\nEpoch 9/100\n67/67 [==============================] - 29s 427ms/step - loss: 0.1756 - accuracy: 0.9334 - val_loss: 0.1951 - val_accuracy: 0.9156\nEpoch 10/100\n67/67 [==============================] - 30s 442ms/step - loss: 0.1572 - accuracy: 0.9407 - val_loss: 0.1934 - val_accuracy: 0.9271\nEpoch 11/100\n67/67 [==============================] - 30s 439ms/step - loss: 0.1622 - accuracy: 0.9367 - val_loss: 0.1918 - val_accuracy: 0.9222\nEpoch 12/100\n67/67 [==============================] - 29s 437ms/step - loss: 0.1549 - accuracy: 0.9421 - val_loss: 0.2104 - val_accuracy: 0.9214\nEpoch 13/100\n67/67 [==============================] - 29s 440ms/step - loss: 0.1426 - accuracy: 0.9467 - val_loss: 0.1585 - val_accuracy: 0.9436\nEpoch 14/100\n67/67 [==============================] - 29s 429ms/step - loss: 0.1368 - accuracy: 0.9481 - val_loss: 0.1725 - val_accuracy: 0.9428\nEpoch 15/100\n67/67 [==============================] - 29s 437ms/step - loss: 0.1270 - accuracy: 0.9551 - val_loss: 0.1576 - val_accuracy: 0.9417\nEpoch 16/100\n67/67 [==============================] - 29s 431ms/step - loss: 0.1136 - accuracy: 0.9551 - val_loss: 0.1608 - val_accuracy: 0.9395\nEpoch 17/100\n67/67 [==============================] - 29s 441ms/step - loss: 0.1124 - accuracy: 0.9572 - val_loss: 0.1708 - val_accuracy: 0.9370\nEpoch 18/100\n67/67 [==============================] - 29s 432ms/step - loss: 0.1044 - accuracy: 0.9624 - val_loss: 0.1593 - val_accuracy: 0.9434\nEpoch 19/100\n67/67 [==============================] - 29s 429ms/step - loss: 0.0949 - accuracy: 0.9639 - val_loss: 0.1542 - val_accuracy: 0.9478\nEpoch 20/100\n67/67 [==============================] - 29s 440ms/step - loss: 0.0949 - accuracy: 0.9654 - val_loss: 0.1513 - val_accuracy: 0.9480\nEpoch 21/100\n67/67 [==============================] - 30s 443ms/step - loss: 0.0862 - accuracy: 0.9674 - val_loss: 0.1906 - val_accuracy: 0.9412\nEpoch 22/100\n67/67 [==============================] - 29s 432ms/step - loss: 0.0721 - accuracy: 0.9722 - val_loss: 0.1524 - val_accuracy: 0.9491\nEpoch 23/100\n67/67 [==============================] - 30s 445ms/step - loss: 0.0763 - accuracy: 0.9727 - val_loss: 0.1646 - val_accuracy: 0.9483\nEpoch 24/100\n67/67 [==============================] - 30s 443ms/step - loss: 0.0691 - accuracy: 0.9737 - val_loss: 0.1715 - val_accuracy: 0.9453\nEpoch 25/100\n67/67 [==============================] - 29s 433ms/step - loss: 0.0583 - accuracy: 0.9780 - val_loss: 0.1680 - val_accuracy: 0.9511\nEpoch 26/100\n67/67 [==============================] - 29s 441ms/step - loss: 0.0596 - accuracy: 0.9787 - val_loss: 0.1650 - val_accuracy: 0.9516\nEpoch 27/100\n67/67 [==============================] - 29s 430ms/step - loss: 0.0607 - accuracy: 0.9767 - val_loss: 0.1729 - val_accuracy: 0.9475\nEpoch 28/100\n67/67 [==============================] - 29s 438ms/step - loss: 0.0561 - accuracy: 0.9789 - val_loss: 0.2202 - val_accuracy: 0.9467\nEpoch 29/100\n67/67 [==============================] - 30s 446ms/step - loss: 0.0500 - accuracy: 0.9804 - val_loss: 0.1776 - val_accuracy: 0.9519\nEpoch 30/100\n67/67 [==============================] - 30s 442ms/step - loss: 0.0469 - accuracy: 0.9829 - val_loss: 0.1840 - val_accuracy: 0.9511\nEpoch 31/100\n67/67 [==============================] - 30s 440ms/step - loss: 0.0408 - accuracy: 0.9850 - val_loss: 0.1762 - val_accuracy: 0.9557\nEpoch 32/100\n67/67 [==============================] - 30s 442ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 0.1765 - val_accuracy: 0.9571\nEpoch 33/100\n67/67 [==============================] - 30s 456ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.1871 - val_accuracy: 0.9533\nEpoch 34/100\n67/67 [==============================] - 29s 434ms/step - loss: 0.0396 - accuracy: 0.9856 - val_loss: 0.1776 - val_accuracy: 0.9511\nEpoch 35/100\n67/67 [==============================] - 29s 431ms/step - loss: 0.0363 - accuracy: 0.9873 - val_loss: 0.2067 - val_accuracy: 0.9318\nEpoch 36/100\n67/67 [==============================] - 29s 427ms/step - loss: 0.0458 - accuracy: 0.9827 - val_loss: 0.1755 - val_accuracy: 0.9403\nEpoch 37/100\n67/67 [==============================] - 29s 424ms/step - loss: 0.0377 - accuracy: 0.9850 - val_loss: 0.1789 - val_accuracy: 0.9500\nEpoch 38/100\n67/67 [==============================] - 29s 441ms/step - loss: 0.0326 - accuracy: 0.9868 - val_loss: 0.2019 - val_accuracy: 0.9549\nEpoch 39/100\n67/67 [==============================] - 29s 437ms/step - loss: 0.0327 - accuracy: 0.9881 - val_loss: 0.1629 - val_accuracy: 0.9544\nEpoch 40/100\n67/67 [==============================] - 29s 435ms/step - loss: 0.0216 - accuracy: 0.9920 - val_loss: 0.2273 - val_accuracy: 0.9557\nEpoch 41/100\n67/67 [==============================] - 29s 441ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.1872 - val_accuracy: 0.9549\nEpoch 42/100\n67/67 [==============================] - 29s 439ms/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 0.2757 - val_accuracy: 0.9513\nEpoch 43/100\n67/67 [==============================] - 29s 436ms/step - loss: 0.0337 - accuracy: 0.9876 - val_loss: 0.2213 - val_accuracy: 0.9574\nEpoch 44/100\n67/67 [==============================] - 30s 440ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.2127 - val_accuracy: 0.9541\nEpoch 45/100\n67/67 [==============================] - 29s 432ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.1968 - val_accuracy: 0.9538\nEpoch 46/100\n67/67 [==============================] - 30s 444ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.2326 - val_accuracy: 0.9535\nEpoch 47/100\n67/67 [==============================] - 30s 444ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.2227 - val_accuracy: 0.9533\nEpoch 48/100\n67/67 [==============================] - 30s 442ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.2679 - val_accuracy: 0.9513\nEpoch 49/100\n67/67 [==============================] - 29s 432ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.2044 - val_accuracy: 0.9513\nEpoch 50/100\n67/67 [==============================] - 30s 445ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.1844 - val_accuracy: 0.9535\nEpoch 51/100\n67/67 [==============================] - 30s 449ms/step - loss: 0.0175 - accuracy: 0.9934 - val_loss: 0.2030 - val_accuracy: 0.9541\nEpoch 52/100\n67/67 [==============================] - 29s 437ms/step - loss: 0.0124 - accuracy: 0.9948 - val_loss: 0.2040 - val_accuracy: 0.9590\nEpoch 53/100\n67/67 [==============================] - 29s 434ms/step - loss: 0.0223 - accuracy: 0.9914 - val_loss: 0.1917 - val_accuracy: 0.9571\nEpoch 54/100\n67/67 [==============================] - 29s 429ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.2785 - val_accuracy: 0.9527\nEpoch 55/100\n67/67 [==============================] - 29s 437ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.3008 - val_accuracy: 0.9494\nEpoch 56/100\n67/67 [==============================] - 29s 440ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.1904 - val_accuracy: 0.9577\nEpoch 57/100\n67/67 [==============================] - 29s 439ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.1903 - val_accuracy: 0.9533\nEpoch 58/100\n67/67 [==============================] - 29s 433ms/step - loss: 0.0159 - accuracy: 0.9934 - val_loss: 0.1973 - val_accuracy: 0.9560\nEpoch 59/100\n67/67 [==============================] - 29s 441ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.2532 - val_accuracy: 0.9563\nEpoch 60/100\n67/67 [==============================] - 30s 442ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 0.1885 - val_accuracy: 0.9544\nEpoch 61/100\n67/67 [==============================] - 29s 435ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.2052 - val_accuracy: 0.9571\nEpoch 62/100\n67/67 [==============================] - 30s 444ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.3008 - val_accuracy: 0.9524\nEpoch 63/100\n67/67 [==============================] - 29s 429ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.2330 - val_accuracy: 0.9555\nEpoch 64/100\n67/67 [==============================] - 29s 434ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.2438 - val_accuracy: 0.9541\nEpoch 65/100\n67/67 [==============================] - 30s 444ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.1969 - val_accuracy: 0.9574\nEpoch 66/100\n67/67 [==============================] - 29s 437ms/step - loss: 0.0176 - accuracy: 0.9932 - val_loss: 0.1937 - val_accuracy: 0.9552\nEpoch 67/100\n67/67 [==============================] - 29s 426ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.2657 - val_accuracy: 0.9530\nEpoch 68/100\n67/67 [==============================] - 29s 435ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.2275 - val_accuracy: 0.9582\nEpoch 69/100\n67/67 [==============================] - 30s 449ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.1954 - val_accuracy: 0.9596\nEpoch 70/100\n67/67 [==============================] - 29s 426ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.2185 - val_accuracy: 0.9615\nEpoch 71/100\n67/67 [==============================] - 29s 428ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.2245 - val_accuracy: 0.9577\nEpoch 72/100\n67/67 [==============================] - 29s 435ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.2451 - val_accuracy: 0.9560\nEpoch 73/100\n67/67 [==============================] - 29s 434ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.2315 - val_accuracy: 0.9555\nEpoch 74/100\n67/67 [==============================] - 29s 434ms/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.2151 - val_accuracy: 0.9557\nEpoch 75/100\n67/67 [==============================] - 29s 428ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.2380 - val_accuracy: 0.9588\nEpoch 76/100\n67/67 [==============================] - 30s 451ms/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.3536 - val_accuracy: 0.9530\nEpoch 77/100\n67/67 [==============================] - 29s 439ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.2093 - val_accuracy: 0.9574\nEpoch 78/100\n67/67 [==============================] - 29s 438ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.2388 - val_accuracy: 0.9574\nEpoch 79/100\n67/67 [==============================] - 29s 434ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.2700 - val_accuracy: 0.9533\nEpoch 80/100\n67/67 [==============================] - 29s 427ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.2181 - val_accuracy: 0.9502\nEpoch 81/100\n67/67 [==============================] - 29s 426ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.2650 - val_accuracy: 0.9577\nEpoch 82/100\n67/67 [==============================] - 29s 440ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.2292 - val_accuracy: 0.9585\nEpoch 83/100\n67/67 [==============================] - 29s 440ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.2381 - val_accuracy: 0.9621\nEpoch 84/100\n67/67 [==============================] - 29s 434ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.2346 - val_accuracy: 0.9615\nEpoch 85/100\n67/67 [==============================] - 29s 440ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.2285 - val_accuracy: 0.9549\nEpoch 86/100\n67/67 [==============================] - 30s 447ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.2368 - val_accuracy: 0.9593\nEpoch 87/100\n67/67 [==============================] - 30s 443ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.3413 - val_accuracy: 0.9497\nEpoch 88/100\n67/67 [==============================] - 29s 438ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.2593 - val_accuracy: 0.9557\nEpoch 89/100\n67/67 [==============================] - 29s 437ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.2574 - val_accuracy: 0.9563\nEpoch 90/100\n67/67 [==============================] - 28s 420ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.3145 - val_accuracy: 0.9519\nEpoch 91/100\n67/67 [==============================] - 31s 457ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.2570 - val_accuracy: 0.9555\nEpoch 92/100\n67/67 [==============================] - 29s 439ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.2220 - val_accuracy: 0.9599\nEpoch 93/100\n67/67 [==============================] - 29s 431ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.2351 - val_accuracy: 0.9579\nEpoch 94/100\n67/67 [==============================] - 30s 445ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.2844 - val_accuracy: 0.9568\nEpoch 95/100\n67/67 [==============================] - 29s 437ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.2592 - val_accuracy: 0.9574\nEpoch 96/100\n67/67 [==============================] - 30s 443ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.2855 - val_accuracy: 0.9599\nEpoch 97/100\n67/67 [==============================] - 30s 441ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.2433 - val_accuracy: 0.9500\nEpoch 98/100\n67/67 [==============================] - 30s 443ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.2645 - val_accuracy: 0.9533\nEpoch 99/100\n67/67 [==============================] - 28s 423ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.2449 - val_accuracy: 0.9568\nEpoch 100/100\n67/67 [==============================] - 29s 436ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.2742 - val_accuracy: 0.9500\nlength of train data:=\n40064\nEpoch 1/50\n220/220 [==============================] - 101s 442ms/step - loss: 0.3195 - accuracy: 0.8533 - val_loss: 0.1796 - val_accuracy: 0.9280\nEpoch 2/50\n220/220 [==============================] - 97s 441ms/step - loss: 0.1947 - accuracy: 0.9262 - val_loss: 0.1214 - val_accuracy: 0.9577\nEpoch 3/50\n220/220 [==============================] - 96s 436ms/step - loss: 0.1627 - accuracy: 0.9394 - val_loss: 0.1157 - val_accuracy: 0.9631\nEpoch 4/50\n220/220 [==============================] - 96s 436ms/step - loss: 0.1415 - accuracy: 0.9495 - val_loss: 0.0989 - val_accuracy: 0.9633\nEpoch 5/50\n220/220 [==============================] - 95s 431ms/step - loss: 0.1265 - accuracy: 0.9544 - val_loss: 0.0933 - val_accuracy: 0.9693\nEpoch 6/50\n220/220 [==============================] - 96s 436ms/step - loss: 0.1141 - accuracy: 0.9596 - val_loss: 0.0893 - val_accuracy: 0.9682\nEpoch 7/50\n220/220 [==============================] - 97s 439ms/step - loss: 0.1017 - accuracy: 0.9631 - val_loss: 0.0756 - val_accuracy: 0.9736\nEpoch 8/50\n220/220 [==============================] - 97s 439ms/step - loss: 0.0950 - accuracy: 0.9655 - val_loss: 0.0796 - val_accuracy: 0.9733\nEpoch 9/50\n220/220 [==============================] - 96s 437ms/step - loss: 0.0977 - accuracy: 0.9661 - val_loss: 0.0688 - val_accuracy: 0.9754\nEpoch 10/50\n220/220 [==============================] - 97s 440ms/step - loss: 0.0819 - accuracy: 0.9708 - val_loss: 0.0728 - val_accuracy: 0.9744\nEpoch 11/50\n220/220 [==============================] - 96s 434ms/step - loss: 0.0795 - accuracy: 0.9700 - val_loss: 0.0788 - val_accuracy: 0.9726\nEpoch 12/50\n220/220 [==============================] - 95s 432ms/step - loss: 0.0716 - accuracy: 0.9737 - val_loss: 0.0598 - val_accuracy: 0.9780\nEpoch 13/50\n220/220 [==============================] - 96s 436ms/step - loss: 0.0729 - accuracy: 0.9737 - val_loss: 0.0583 - val_accuracy: 0.9765\nEpoch 14/50\n220/220 [==============================] - 97s 443ms/step - loss: 0.0620 - accuracy: 0.9771 - val_loss: 0.0537 - val_accuracy: 0.9799\nEpoch 15/50\n220/220 [==============================] - 98s 446ms/step - loss: 0.0626 - accuracy: 0.9772 - val_loss: 0.0568 - val_accuracy: 0.9796\nEpoch 16/50\n220/220 [==============================] - 95s 433ms/step - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.0559 - val_accuracy: 0.9806\nEpoch 17/50\n220/220 [==============================] - 96s 434ms/step - loss: 0.0530 - accuracy: 0.9798 - val_loss: 0.0562 - val_accuracy: 0.9791\nEpoch 18/50\n220/220 [==============================] - 95s 434ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.0612 - val_accuracy: 0.9779\nEpoch 19/50\n220/220 [==============================] - 95s 431ms/step - loss: 0.0459 - accuracy: 0.9828 - val_loss: 0.0494 - val_accuracy: 0.9821\nEpoch 20/50\n220/220 [==============================] - 96s 433ms/step - loss: 0.0417 - accuracy: 0.9842 - val_loss: 0.0519 - val_accuracy: 0.9819\nEpoch 21/50\n220/220 [==============================] - 96s 437ms/step - loss: 0.0417 - accuracy: 0.9844 - val_loss: 0.0569 - val_accuracy: 0.9810\nEpoch 22/50\n220/220 [==============================] - 96s 435ms/step - loss: 0.0377 - accuracy: 0.9855 - val_loss: 0.0644 - val_accuracy: 0.9818\nEpoch 23/50\n220/220 [==============================] - 94s 429ms/step - loss: 0.0354 - accuracy: 0.9870 - val_loss: 0.0569 - val_accuracy: 0.9823\nEpoch 24/50\n220/220 [==============================] - 94s 429ms/step - loss: 0.0359 - accuracy: 0.9867 - val_loss: 0.0792 - val_accuracy: 0.9745\nEpoch 25/50\n220/220 [==============================] - 95s 431ms/step - loss: 0.0339 - accuracy: 0.9865 - val_loss: 0.0537 - val_accuracy: 0.9814\nEpoch 26/50\n220/220 [==============================] - 96s 435ms/step - loss: 0.0321 - accuracy: 0.9880 - val_loss: 0.0616 - val_accuracy: 0.9798\nEpoch 27/50\n220/220 [==============================] - 96s 437ms/step - loss: 0.0356 - accuracy: 0.9864 - val_loss: 0.0599 - val_accuracy: 0.9814\nEpoch 28/50\n220/220 [==============================] - 96s 435ms/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.0559 - val_accuracy: 0.9819\nEpoch 29/50\n220/220 [==============================] - 96s 435ms/step - loss: 0.0298 - accuracy: 0.9892 - val_loss: 0.0607 - val_accuracy: 0.9815\nEpoch 30/50\n220/220 [==============================] - 96s 437ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.0599 - val_accuracy: 0.9805\nEpoch 31/50\n220/220 [==============================] - 96s 436ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.0609 - val_accuracy: 0.9834\nEpoch 32/50\n220/220 [==============================] - 95s 433ms/step - loss: 0.0257 - accuracy: 0.9904 - val_loss: 0.0681 - val_accuracy: 0.9823\nEpoch 33/50\n220/220 [==============================] - 95s 433ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.0604 - val_accuracy: 0.9839\nEpoch 34/50\n220/220 [==============================] - 96s 438ms/step - loss: 0.0238 - accuracy: 0.9908 - val_loss: 0.0575 - val_accuracy: 0.9822\nEpoch 35/50\n220/220 [==============================] - 96s 434ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.0668 - val_accuracy: 0.9815\nEpoch 36/50\n220/220 [==============================] - 97s 443ms/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.0698 - val_accuracy: 0.9812\nEpoch 37/50\n220/220 [==============================] - 96s 438ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.0674 - val_accuracy: 0.9837\nEpoch 38/50\n220/220 [==============================] - 97s 440ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.0619 - val_accuracy: 0.9836\nEpoch 39/50\n220/220 [==============================] - 96s 435ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.0640 - val_accuracy: 0.9841\nEpoch 40/50\n220/220 [==============================] - 96s 438ms/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 0.0612 - val_accuracy: 0.9833\nEpoch 41/50\n220/220 [==============================] - 97s 440ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.0583 - val_accuracy: 0.9834\nEpoch 42/50\n220/220 [==============================] - 97s 442ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.0544 - val_accuracy: 0.9826\nEpoch 43/50\n220/220 [==============================] - 97s 441ms/step - loss: 0.0197 - accuracy: 0.9924 - val_loss: 0.0718 - val_accuracy: 0.9825\nEpoch 44/50\n220/220 [==============================] - 96s 436ms/step - loss: 0.0188 - accuracy: 0.9929 - val_loss: 0.0756 - val_accuracy: 0.9830\nEpoch 45/50\n220/220 [==============================] - 97s 437ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0601 - val_accuracy: 0.9844\nEpoch 46/50\n220/220 [==============================] - 98s 444ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0670 - val_accuracy: 0.9833\nEpoch 47/50\n220/220 [==============================] - 97s 439ms/step - loss: 0.0177 - accuracy: 0.9934 - val_loss: 0.0786 - val_accuracy: 0.9814\nEpoch 48/50\n220/220 [==============================] - 96s 435ms/step - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0696 - val_accuracy: 0.9833\nEpoch 49/50\n220/220 [==============================] - 96s 436ms/step - loss: 0.0190 - accuracy: 0.9930 - val_loss: 0.0639 - val_accuracy: 0.9819\nEpoch 50/50\n220/220 [==============================] - 97s 442ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.0648 - val_accuracy: 0.9837\nlength of remaining unlabled data:=\n344\nlength of train data:=\n40355\nEpoch 1/50\n221/221 [==============================] - 101s 439ms/step - loss: 0.3302 - accuracy: 0.8484 - val_loss: 0.2052 - val_accuracy: 0.9167\nEpoch 2/50\n221/221 [==============================] - 98s 444ms/step - loss: 0.2043 - accuracy: 0.9194 - val_loss: 0.1754 - val_accuracy: 0.9422\nEpoch 3/50\n221/221 [==============================] - 98s 444ms/step - loss: 0.1646 - accuracy: 0.9391 - val_loss: 0.1172 - val_accuracy: 0.9557\nEpoch 4/50\n221/221 [==============================] - 98s 442ms/step - loss: 0.1349 - accuracy: 0.9493 - val_loss: 0.1045 - val_accuracy: 0.9596\nEpoch 5/50\n221/221 [==============================] - 98s 444ms/step - loss: 0.1199 - accuracy: 0.9560 - val_loss: 0.1079 - val_accuracy: 0.9622\nEpoch 6/50\n221/221 [==============================] - 97s 441ms/step - loss: 0.1103 - accuracy: 0.9600 - val_loss: 0.0966 - val_accuracy: 0.9650\nEpoch 7/50\n221/221 [==============================] - 97s 439ms/step - loss: 0.0998 - accuracy: 0.9646 - val_loss: 0.0837 - val_accuracy: 0.9685\nEpoch 8/50\n221/221 [==============================] - 98s 443ms/step - loss: 0.1190 - accuracy: 0.9598 - val_loss: 0.0846 - val_accuracy: 0.9679\nEpoch 9/50\n221/221 [==============================] - 96s 433ms/step - loss: 0.0917 - accuracy: 0.9666 - val_loss: 0.0816 - val_accuracy: 0.9680\nEpoch 10/50\n221/221 [==============================] - 97s 441ms/step - loss: 0.0865 - accuracy: 0.9682 - val_loss: 0.0859 - val_accuracy: 0.9689\nEpoch 11/50\n221/221 [==============================] - 96s 435ms/step - loss: 0.0786 - accuracy: 0.9712 - val_loss: 0.0785 - val_accuracy: 0.9702\nEpoch 12/50\n221/221 [==============================] - 98s 442ms/step - loss: 0.0742 - accuracy: 0.9727 - val_loss: 0.0817 - val_accuracy: 0.9679\nEpoch 13/50\n221/221 [==============================] - 97s 439ms/step - loss: 0.0722 - accuracy: 0.9741 - val_loss: 0.0699 - val_accuracy: 0.9745\nEpoch 14/50\n221/221 [==============================] - 96s 435ms/step - loss: 0.0708 - accuracy: 0.9743 - val_loss: 0.0724 - val_accuracy: 0.9724\nEpoch 15/50\n221/221 [==============================] - 98s 442ms/step - loss: 0.0660 - accuracy: 0.9766 - val_loss: 0.0701 - val_accuracy: 0.9739\nEpoch 16/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0620 - accuracy: 0.9769 - val_loss: 0.0671 - val_accuracy: 0.9763\nEpoch 17/50\n221/221 [==============================] - 97s 440ms/step - loss: 0.0568 - accuracy: 0.9799 - val_loss: 0.0657 - val_accuracy: 0.9758\nEpoch 18/50\n221/221 [==============================] - 98s 441ms/step - loss: 0.0571 - accuracy: 0.9802 - val_loss: 0.0709 - val_accuracy: 0.9740\nEpoch 19/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0707 - accuracy: 0.9755 - val_loss: 0.0711 - val_accuracy: 0.9739\nEpoch 20/50\n221/221 [==============================] - 96s 435ms/step - loss: 0.0522 - accuracy: 0.9817 - val_loss: 0.0668 - val_accuracy: 0.9763\nEpoch 21/50\n221/221 [==============================] - 98s 443ms/step - loss: 0.0469 - accuracy: 0.9834 - val_loss: 0.0799 - val_accuracy: 0.9726\nEpoch 22/50\n221/221 [==============================] - 97s 439ms/step - loss: 0.0436 - accuracy: 0.9841 - val_loss: 0.0625 - val_accuracy: 0.9785\nEpoch 23/50\n221/221 [==============================] - 97s 440ms/step - loss: 0.1929 - accuracy: 0.9020 - val_loss: 0.1013 - val_accuracy: 0.9564\nEpoch 24/50\n221/221 [==============================] - 96s 437ms/step - loss: 0.0554 - accuracy: 0.9797 - val_loss: 0.0647 - val_accuracy: 0.9769\nEpoch 25/50\n221/221 [==============================] - 96s 435ms/step - loss: 0.0449 - accuracy: 0.9839 - val_loss: 0.0686 - val_accuracy: 0.9770\nEpoch 26/50\n221/221 [==============================] - 97s 440ms/step - loss: 0.0422 - accuracy: 0.9845 - val_loss: 0.0694 - val_accuracy: 0.9758\nEpoch 27/50\n221/221 [==============================] - 96s 436ms/step - loss: 0.0371 - accuracy: 0.9860 - val_loss: 0.0634 - val_accuracy: 0.9781\nEpoch 28/50\n221/221 [==============================] - 97s 437ms/step - loss: 0.0379 - accuracy: 0.9864 - val_loss: 0.0848 - val_accuracy: 0.9721\nEpoch 29/50\n221/221 [==============================] - 97s 441ms/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: 0.0645 - val_accuracy: 0.9784\nEpoch 30/50\n221/221 [==============================] - 96s 436ms/step - loss: 0.0348 - accuracy: 0.9867 - val_loss: 0.0638 - val_accuracy: 0.9787\nEpoch 31/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0303 - accuracy: 0.9886 - val_loss: 0.0705 - val_accuracy: 0.9763\nEpoch 32/50\n221/221 [==============================] - 97s 440ms/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 0.0718 - val_accuracy: 0.9781\nEpoch 33/50\n221/221 [==============================] - 97s 439ms/step - loss: 0.0309 - accuracy: 0.9881 - val_loss: 0.0719 - val_accuracy: 0.9777\nEpoch 34/50\n221/221 [==============================] - 97s 439ms/step - loss: 0.0299 - accuracy: 0.9881 - val_loss: 0.0636 - val_accuracy: 0.9808\nEpoch 35/50\n221/221 [==============================] - 96s 436ms/step - loss: 0.0263 - accuracy: 0.9907 - val_loss: 0.0714 - val_accuracy: 0.9767\nEpoch 36/50\n221/221 [==============================] - 96s 437ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 0.0660 - val_accuracy: 0.9799\nEpoch 37/50\n221/221 [==============================] - 96s 435ms/step - loss: 0.0247 - accuracy: 0.9903 - val_loss: 0.0662 - val_accuracy: 0.9792\nEpoch 38/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0257 - accuracy: 0.9902 - val_loss: 0.0711 - val_accuracy: 0.9764\nEpoch 39/50\n221/221 [==============================] - 95s 428ms/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 0.0646 - val_accuracy: 0.9806\nEpoch 40/50\n221/221 [==============================] - 95s 432ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.0717 - val_accuracy: 0.9765\nEpoch 41/50\n221/221 [==============================] - 95s 429ms/step - loss: 0.0226 - accuracy: 0.9910 - val_loss: 0.0777 - val_accuracy: 0.9765\nEpoch 42/50\n221/221 [==============================] - 94s 426ms/step - loss: 0.0233 - accuracy: 0.9910 - val_loss: 0.0895 - val_accuracy: 0.9759\nEpoch 43/50\n221/221 [==============================] - 96s 433ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0760 - val_accuracy: 0.9772\nEpoch 44/50\n221/221 [==============================] - 95s 429ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0802 - val_accuracy: 0.9753\nEpoch 45/50\n221/221 [==============================] - 95s 427ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.0672 - val_accuracy: 0.9809\nEpoch 46/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 0.0763 - val_accuracy: 0.9804\nEpoch 47/50\n221/221 [==============================] - 97s 437ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0660 - val_accuracy: 0.9805\nEpoch 48/50\n221/221 [==============================] - 96s 433ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.0711 - val_accuracy: 0.9802\nEpoch 49/50\n221/221 [==============================] - 97s 440ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.0659 - val_accuracy: 0.9802\nEpoch 50/50\n221/221 [==============================] - 97s 441ms/step - loss: 0.0187 - accuracy: 0.9929 - val_loss: 0.0855 - val_accuracy: 0.9757\nlength of remaining unlabled data:=\n53\nlength of train data:=\n40400\nEpoch 1/50\n221/221 [==============================] - 101s 438ms/step - loss: 0.3424 - accuracy: 0.8424 - val_loss: 0.1967 - val_accuracy: 0.9191\nEpoch 2/50\n221/221 [==============================] - 96s 433ms/step - loss: 0.1995 - accuracy: 0.9233 - val_loss: 0.1548 - val_accuracy: 0.9426\nEpoch 3/50\n221/221 [==============================] - 97s 440ms/step - loss: 0.1638 - accuracy: 0.9384 - val_loss: 0.1192 - val_accuracy: 0.9569\nEpoch 4/50\n221/221 [==============================] - 97s 437ms/step - loss: 0.1426 - accuracy: 0.9477 - val_loss: 0.1162 - val_accuracy: 0.9586\nEpoch 5/50\n221/221 [==============================] - 97s 441ms/step - loss: 0.1199 - accuracy: 0.9552 - val_loss: 0.0994 - val_accuracy: 0.9615\nEpoch 6/50\n221/221 [==============================] - 97s 437ms/step - loss: 0.1084 - accuracy: 0.9588 - val_loss: 0.0884 - val_accuracy: 0.9652\nEpoch 7/50\n221/221 [==============================] - 97s 437ms/step - loss: 0.1001 - accuracy: 0.9623 - val_loss: 0.0908 - val_accuracy: 0.9644\nEpoch 8/50\n221/221 [==============================] - 97s 436ms/step - loss: 0.0952 - accuracy: 0.9649 - val_loss: 0.0840 - val_accuracy: 0.9691\nEpoch 9/50\n221/221 [==============================] - 96s 434ms/step - loss: 0.0881 - accuracy: 0.9680 - val_loss: 0.0813 - val_accuracy: 0.9681\nEpoch 10/50\n221/221 [==============================] - 98s 443ms/step - loss: 0.0853 - accuracy: 0.9688 - val_loss: 0.0935 - val_accuracy: 0.9625\nEpoch 11/50\n221/221 [==============================] - 96s 433ms/step - loss: 0.0790 - accuracy: 0.9711 - val_loss: 0.0785 - val_accuracy: 0.9711\nEpoch 12/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0701 - accuracy: 0.9735 - val_loss: 0.0835 - val_accuracy: 0.9707\nEpoch 13/50\n221/221 [==============================] - 97s 439ms/step - loss: 0.0663 - accuracy: 0.9752 - val_loss: 0.0802 - val_accuracy: 0.9711\nEpoch 14/50\n221/221 [==============================] - 97s 439ms/step - loss: 0.0646 - accuracy: 0.9761 - val_loss: 0.0793 - val_accuracy: 0.9727\nEpoch 15/50\n221/221 [==============================] - 97s 439ms/step - loss: 0.0580 - accuracy: 0.9793 - val_loss: 0.0709 - val_accuracy: 0.9731\nEpoch 16/50\n221/221 [==============================] - 97s 441ms/step - loss: 0.0544 - accuracy: 0.9794 - val_loss: 0.0768 - val_accuracy: 0.9724\nEpoch 17/50\n221/221 [==============================] - 97s 437ms/step - loss: 0.0520 - accuracy: 0.9809 - val_loss: 0.0700 - val_accuracy: 0.9732\nEpoch 18/50\n221/221 [==============================] - 97s 440ms/step - loss: 0.0490 - accuracy: 0.9815 - val_loss: 0.0715 - val_accuracy: 0.9739\nEpoch 19/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0459 - accuracy: 0.9826 - val_loss: 0.0793 - val_accuracy: 0.9756\nEpoch 20/50\n221/221 [==============================] - 96s 436ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 0.0750 - val_accuracy: 0.9749\nEpoch 21/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0475 - accuracy: 0.9830 - val_loss: 0.0668 - val_accuracy: 0.9769\nEpoch 22/50\n221/221 [==============================] - 96s 436ms/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.0793 - val_accuracy: 0.9716\nEpoch 23/50\n221/221 [==============================] - 97s 437ms/step - loss: 0.0373 - accuracy: 0.9857 - val_loss: 0.0743 - val_accuracy: 0.9745\nEpoch 24/50\n221/221 [==============================] - 96s 434ms/step - loss: 0.0346 - accuracy: 0.9876 - val_loss: 0.0716 - val_accuracy: 0.9758\nEpoch 25/50\n221/221 [==============================] - 96s 434ms/step - loss: 0.0346 - accuracy: 0.9874 - val_loss: 0.0929 - val_accuracy: 0.9672\nEpoch 26/50\n221/221 [==============================] - 96s 437ms/step - loss: 0.0319 - accuracy: 0.9883 - val_loss: 0.0764 - val_accuracy: 0.9749\nEpoch 27/50\n221/221 [==============================] - 96s 434ms/step - loss: 0.0306 - accuracy: 0.9891 - val_loss: 0.0813 - val_accuracy: 0.9745\nEpoch 28/50\n221/221 [==============================] - 96s 437ms/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.0716 - val_accuracy: 0.9767\nEpoch 29/50\n221/221 [==============================] - 97s 438ms/step - loss: 0.0285 - accuracy: 0.9890 - val_loss: 0.0741 - val_accuracy: 0.9759\nEpoch 30/50\n221/221 [==============================] - 96s 437ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.0793 - val_accuracy: 0.9721\nEpoch 31/50\n221/221 [==============================] - 96s 436ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.0696 - val_accuracy: 0.9762\nEpoch 32/50\n221/221 [==============================] - 96s 436ms/step - loss: 0.0261 - accuracy: 0.9901 - val_loss: 0.0782 - val_accuracy: 0.9763\nEpoch 33/50\n221/221 [==============================] - 95s 431ms/step - loss: 0.0279 - accuracy: 0.9893 - val_loss: 0.0750 - val_accuracy: 0.9757\nEpoch 34/50\n221/221 [==============================] - 95s 430ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.0701 - val_accuracy: 0.9774\nEpoch 35/50\n221/221 [==============================] - 95s 428ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.0723 - val_accuracy: 0.9793\nEpoch 36/50\n221/221 [==============================] - 96s 436ms/step - loss: 0.0255 - accuracy: 0.9907 - val_loss: 0.0837 - val_accuracy: 0.9787\nEpoch 37/50\n221/221 [==============================] - 95s 429ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.0825 - val_accuracy: 0.9757\nEpoch 38/50\n221/221 [==============================] - 95s 430ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.0770 - val_accuracy: 0.9753\nEpoch 39/50\n221/221 [==============================] - 95s 428ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.0763 - val_accuracy: 0.9788\nEpoch 40/50\n221/221 [==============================] - 96s 433ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.0742 - val_accuracy: 0.9794\nEpoch 41/50\n221/221 [==============================] - 96s 434ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 0.0932 - val_accuracy: 0.9759\nEpoch 42/50\n221/221 [==============================] - 95s 432ms/step - loss: 0.0201 - accuracy: 0.9923 - val_loss: 0.0882 - val_accuracy: 0.9752\nEpoch 43/50\n221/221 [==============================] - 95s 428ms/step - loss: 0.0219 - accuracy: 0.9917 - val_loss: 0.0827 - val_accuracy: 0.9776\nEpoch 44/50\n221/221 [==============================] - 96s 434ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0906 - val_accuracy: 0.9773\nEpoch 45/50\n221/221 [==============================] - 99s 449ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0876 - val_accuracy: 0.9780\nEpoch 46/50\n221/221 [==============================] - 95s 429ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.0828 - val_accuracy: 0.9780\nEpoch 47/50\n221/221 [==============================] - 96s 432ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.0795 - val_accuracy: 0.9766\nEpoch 48/50\n221/221 [==============================] - 96s 434ms/step - loss: 0.0170 - accuracy: 0.9936 - val_loss: 0.0923 - val_accuracy: 0.9797\nEpoch 49/50\n221/221 [==============================] - 96s 433ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.0806 - val_accuracy: 0.9780\nEpoch 50/50\n221/221 [==============================] - 96s 433ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0799 - val_accuracy: 0.9781\nlength of remaining unlabled data:=\n8\n","output_type":"stream"}]},{"cell_type":"code","source":"test_res=(model.predict(X_test) > 0.5).astype(\"int32\")\ntest_res=test_res.flatten()\ny_test_c = y_test.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T10:03:24.962874Z","iopub.execute_input":"2022-04-18T10:03:24.963136Z","iopub.status.idle":"2022-04-18T10:03:29.007842Z","shell.execute_reply.started":"2022-04-18T10:03:24.963100Z","shell.execute_reply":"2022-04-18T10:03:29.007103Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in range(0,len(y_test_c)):\n    if(y_test_c[i]==test_res[i]):\n        count=count+1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T10:03:29.011585Z","iopub.execute_input":"2022-04-18T10:03:29.011812Z","iopub.status.idle":"2022-04-18T10:03:29.020310Z","shell.execute_reply.started":"2022-04-18T10:03:29.011768Z","shell.execute_reply":"2022-04-18T10:03:29.019597Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"4317\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy=(count/len(test_res))*100","metadata":{"execution":{"iopub.status.busy":"2022-04-18T10:03:29.021566Z","iopub.execute_input":"2022-04-18T10:03:29.022275Z","iopub.status.idle":"2022-04-18T10:03:29.029491Z","shell.execute_reply.started":"2022-04-18T10:03:29.022236Z","shell.execute_reply":"2022-04-18T10:03:29.028710Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy at 30% labled data\",accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T10:03:29.030490Z","iopub.execute_input":"2022-04-18T10:03:29.030733Z","iopub.status.idle":"2022-04-18T10:03:29.038700Z","shell.execute_reply.started":"2022-04-18T10:03:29.030701Z","shell.execute_reply":"2022-04-18T10:03:29.037938Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Accuracy at 30% labled data 96.14699331848551\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_test,test_res, target_names = ['Fake','Real']))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T10:03:29.039919Z","iopub.execute_input":"2022-04-18T10:03:29.040312Z","iopub.status.idle":"2022-04-18T10:03:29.061270Z","shell.execute_reply.started":"2022-04-18T10:03:29.040277Z","shell.execute_reply":"2022-04-18T10:03:29.060474Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Fake       0.98      0.94      0.96      2298\n        Real       0.94      0.98      0.96      2192\n\n    accuracy                           0.96      4490\n   macro avg       0.96      0.96      0.96      4490\nweighted avg       0.96      0.96      0.96      4490\n\n","output_type":"stream"}]}]}